{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apache Spark\n",
    "\n",
    "1. Apache Spark is an open source distributed computing system to process large scale data (big data).\n",
    "2. It distributes the data and process them in parallel.\n",
    "3. It is written in Scala. It provides development APIs (libraries) in Scala, Java, Python and R.\n",
    "4. Spark can run stadalone or most frequently on Hadoop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Apache Spark Work?\n",
    "\n",
    "Hadoop MapReduce is a programming model for processing big data sets with a parallel, distributed algorithm. Developers can write massively parallelized operators, without having to worry about work distribution, and fault tolerance. However, a challenge to MapReduce is the sequential multi-step process it takes to run a job. With each step, MapReduce reads data from the cluster, performs operations, and writes the results back to HDFS. Because each step requires a disk read, and write, MapReduce jobs are slower due to the latency of disk I/O.\n",
    "\n",
    "Spark was created to address the limitations to MapReduce, by doing processing in-memory, reducing the number of steps in a job, and by reusing data across multiple parallel operations. With Spark, only one-step is needed where data is read into memory, operations performed, and the results written backâ€”resulting in a much faster execution. Spark also reuses data by using an in-memory cache to greatly speed up machine learning algorithms that repeatedly call a function on the same dataset. Data re-use is accomplished through the creation of DataFrames, an abstraction over Resilient Distributed Dataset (RDD), which is a collection of objects that is cached in memory, and reused in multiple Spark operations. This dramatically lowers the latency making Spark multiple times faster than MapReduce, especially when doing machine learning, and interactive analytics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of Apache Spark\n",
    "\n",
    "1. Fast: Through in-memory caching, and optimized query execution, Spark can run fast analytic queries against data of any size.\n",
    "\n",
    "2. Developer friendly: Apache Spark natively supports Java, Scala, R, and Python, giving you a variety of languages for building your applications. These APIs make it easy for your developers, because they hide the complexity of distributed processing behind simple, high-level operators that dramatically lowers the amount of code required.\n",
    "\n",
    "3. Multiple workloads: Apache Spark comes with the ability to run multiple workloads, including interactive queries, real-time analytics, machine learning, and graph processing. One application can combine multiple workloads seamlessly.\n",
    "\n",
    "4. Data Integration: Seamless integration with various data sources and frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Spark Workloads\n",
    "\n",
    "1. Spark Core: Foundation for the platform. It consists of runtime/compute engine to process the data. It is responsible for memory management, fault recovery, scheduling, distributing & monitoring jobs, and interacting with storage systems. Spark Core is exposed through APIs.\n",
    "\n",
    "2. Streaming: Real time data processing and analytics.\n",
    "\n",
    "3. SQL: Run interactive queries.\n",
    "\n",
    "4. MLlib: Build and train machine learning models.\n",
    "\n",
    "5. GraphX: Graph processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Spark on Cloud\n",
    "1. AWS: Amazon EMR (Elastic Map Reduce)\n",
    "2. GCP: Dataproc\n",
    "3. Azure: Azure Databricks\n",
    "4. Databricks Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
